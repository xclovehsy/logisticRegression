{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21c6f58e-eb43-4391-ae87-db721cd8391c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     花萼长  花萼宽  花瓣长  花瓣宽   品种\n",
      "0    5.1  3.5  1.4  0.2  0.0\n",
      "1    4.9  3.0  1.4  0.2  0.0\n",
      "2    4.7  3.2  1.3  0.2  0.0\n",
      "3    4.6  3.1  1.5  0.2  0.0\n",
      "4    5.0  3.6  1.4  0.2  0.0\n",
      "..   ...  ...  ...  ...  ...\n",
      "145  6.7  3.0  5.2  2.3  2.0\n",
      "146  6.3  2.5  5.0  1.9  2.0\n",
      "147  6.5  3.0  5.2  2.0  2.0\n",
      "148  6.2  3.4  5.4  2.3  2.0\n",
      "149  5.9  3.0  5.1  1.8  2.0\n",
      "\n",
      "[150 rows x 5 columns]\n",
      "==== classifier 0 train begin ====\n",
      "epoch=0, cost=0.6931471805599453\n",
      "epoch=100, cost=0.05769593643181581\n",
      "epoch=200, cost=0.031218910678123057\n",
      "epoch=300, cost=0.02174329009269675\n",
      "epoch=400, cost=0.016815394643394294\n",
      "epoch=500, cost=0.013775009694066047\n",
      "epoch=600, cost=0.01170341736321661\n",
      "epoch=700, cost=0.010196900264913026\n",
      "epoch=800, cost=0.009049599375363178\n",
      "epoch=900, cost=0.008145275264132801\n",
      "epoch=1000, cost=0.00741320702141016\n",
      "epoch=1100, cost=0.006807838207383416\n",
      "epoch=1200, cost=0.006298465903016461\n",
      "epoch=1300, cost=0.0058636245809886725\n",
      "epoch=1400, cost=0.005487843834623663\n",
      "epoch=1500, cost=0.005159684898016107\n",
      "epoch=1600, cost=0.004870503030647037\n",
      "epoch=1700, cost=0.004613640431742335\n",
      "epoch=1800, cost=0.004383884272576204\n",
      "epoch=1900, cost=0.004177093362547661\n",
      "epoch=2000, cost=0.003989935154777518\n",
      "epoch=2100, cost=0.003819696769311579\n",
      "epoch=2200, cost=0.0036641467787591284\n",
      "epoch=2300, cost=0.003521432502639101\n",
      "epoch=2400, cost=0.003390002585919452\n",
      "epoch=2500, cost=0.0032685478731701834\n",
      "epoch=2600, cost=0.003155955716306689\n",
      "epoch=2700, cost=0.0030512742784633497\n",
      "epoch=2800, cost=0.002953684367665309\n",
      "epoch=2900, cost=0.0028624770066676985\n",
      "epoch=3000, cost=0.002777035418212527\n",
      "epoch=3100, cost=0.00269682044191084\n",
      "epoch=3200, cost=0.002621358642090709\n",
      "epoch=3300, cost=0.0025502325434410542\n",
      "epoch=3400, cost=0.002483072562262207\n",
      "epoch=3500, cost=0.0024195502987748394\n",
      "epoch=3600, cost=0.002359372929417597\n",
      "epoch=3700, cost=0.0023022784938526706\n",
      "epoch=3800, cost=0.0022480319141081014\n",
      "epoch=3900, cost=0.0021964216162423658\n",
      "epoch=4000, cost=0.002147256650533459\n",
      "epoch=4100, cost=0.002100364226246798\n",
      "epoch=4200, cost=0.002055587592836686\n",
      "epoch=4300, cost=0.002012784211963084\n",
      "epoch=4400, cost=0.0019718241746972537\n",
      "epoch=4500, cost=0.001932588826304595\n",
      "epoch=4600, cost=0.001894969567455278\n",
      "epoch=4700, cost=0.0018588668059518966\n",
      "epoch=4800, cost=0.0018241890373299951\n",
      "epoch=4900, cost=0.0017908520361779512\n",
      "==== classifier 1 train begin ====\n",
      "epoch=0, cost=0.6931471805599453\n",
      "epoch=100, cost=0.5661885083341962\n",
      "epoch=200, cost=0.5541240140533878\n",
      "epoch=300, cost=0.5449616881929672\n",
      "epoch=400, cost=0.5378591091057584\n",
      "epoch=500, cost=0.5322483271196223\n",
      "epoch=600, cost=0.527729692043432\n",
      "epoch=700, cost=0.5240203123007218\n",
      "epoch=800, cost=0.5209182409870662\n",
      "epoch=900, cost=0.5182779116940538\n",
      "epoch=1000, cost=0.5159933315736952\n",
      "epoch=1100, cost=0.5139865377394301\n",
      "epoch=1200, cost=0.5121996116731968\n",
      "epoch=1300, cost=0.5105891060861131\n",
      "epoch=1400, cost=0.5091221184094901\n",
      "epoch=1500, cost=0.5077734978258979\n",
      "epoch=1600, cost=0.5065238399885856\n",
      "epoch=1700, cost=0.5053580343983641\n",
      "epoch=1800, cost=0.5042642032427095\n",
      "epoch=1900, cost=0.5032329200752228\n",
      "epoch=2000, cost=0.5022566302941949\n",
      "epoch=2100, cost=0.5013292183419763\n",
      "epoch=2200, cost=0.5004456824005866\n",
      "epoch=2300, cost=0.4996018884088187\n",
      "epoch=2400, cost=0.4987943829990249\n",
      "epoch=2500, cost=0.49802025046820614\n",
      "epoch=2600, cost=0.4972770028461594\n",
      "epoch=2700, cost=0.49656249497172\n",
      "epoch=2800, cost=0.4958748585583657\n",
      "epoch=2900, cost=0.4952124507457358\n",
      "epoch=3000, cost=0.49457381374995907\n",
      "epoch=3100, cost=0.49395764305311324\n",
      "epoch=3200, cost=0.4933627621888464\n",
      "epoch=3300, cost=0.49278810264326495\n",
      "epoch=3400, cost=0.49223268773802353\n",
      "epoch=3500, cost=0.49169561962557473\n",
      "epoch=3600, cost=0.4911760687262143\n",
      "epoch=3700, cost=0.49067326508873643\n",
      "epoch=3800, cost=0.4901864912728788\n",
      "epoch=3900, cost=0.48971507644101814\n",
      "epoch=4000, cost=0.4892583914152784\n",
      "epoch=4100, cost=0.4888158445092306\n",
      "epoch=4200, cost=0.4883868779843842\n",
      "epoch=4300, cost=0.4879709650134978\n",
      "epoch=4400, cost=0.4875676070574855\n",
      "epoch=4500, cost=0.4871763315819883\n",
      "epoch=4600, cost=0.4867966900547643\n",
      "epoch=4700, cost=0.48642825617685886\n",
      "epoch=4800, cost=0.48607062430980147\n",
      "epoch=4900, cost=0.4857234080683734\n",
      "==== classifier 2 train begin ====\n",
      "epoch=0, cost=0.6931471805599453\n",
      "epoch=100, cost=0.2872690890587511\n",
      "epoch=200, cost=0.23506571439822718\n",
      "epoch=300, cost=0.2054680739499398\n",
      "epoch=400, cost=0.185509638890949\n",
      "epoch=500, cost=0.1709812328345595\n",
      "epoch=600, cost=0.15988278494394456\n",
      "epoch=700, cost=0.1511038709860744\n",
      "epoch=800, cost=0.14397100008529218\n",
      "epoch=900, cost=0.1380501744809375\n",
      "epoch=1000, cost=0.13304861124247713\n",
      "epoch=1100, cost=0.12876143491616657\n",
      "epoch=1200, cost=0.12504089453234318\n",
      "epoch=1300, cost=0.12177769447478988\n",
      "epoch=1400, cost=0.11888920887401734\n",
      "epoch=1500, cost=0.116311786199456\n",
      "epoch=1600, cost=0.11399557701834338\n",
      "epoch=1700, cost=0.11190096900467847\n",
      "epoch=1800, cost=0.10999607474785444\n",
      "epoch=1900, cost=0.10825492633630489\n",
      "epoch=2000, cost=0.10665615489376447\n",
      "epoch=2100, cost=0.1051820094333518\n",
      "epoch=2200, cost=0.10381761734835515\n",
      "epoch=2300, cost=0.10255041974639234\n",
      "epoch=2400, cost=0.10136973514808668\n",
      "epoch=2500, cost=0.10026641868729029\n",
      "epoch=2600, cost=0.09923259323508385\n",
      "epoch=2700, cost=0.09826143530280218\n",
      "epoch=2800, cost=0.09734700310174844\n",
      "epoch=2900, cost=0.09648409735960313\n",
      "epoch=3000, cost=0.09566814781835653\n",
      "epoch=3100, cost=0.09489512003543604\n",
      "epoch=3200, cost=0.09416143836163182\n",
      "epoch=3300, cost=0.09346392190246483\n",
      "epoch=3400, cost=0.09279973097160858\n",
      "epoch=3500, cost=0.09216632207779796\n",
      "epoch=3600, cost=0.09156140989446569\n",
      "epoch=3700, cost=0.09098293497593594\n",
      "epoch=3800, cost=0.09042903622847197\n",
      "epoch=3900, cost=0.08989802733579545\n",
      "epoch=4000, cost=0.08938837648940506\n",
      "epoch=4100, cost=0.08889868889349552\n",
      "epoch=4200, cost=0.08842769160954851\n",
      "epoch=4300, cost=0.08797422038207217\n",
      "epoch=4400, cost=0.08753720814856955\n",
      "epoch=4500, cost=0.0871156749867405\n",
      "epoch=4600, cost=0.08670871929258218\n",
      "epoch=4700, cost=0.08631551001631832\n",
      "epoch=4800, cost=0.08593527981043068\n",
      "epoch=4900, cost=0.08556731896663128\n",
      "theta_list=[array([[ 0.4529073 ,  0.76245023,  2.41484628, -3.90431906, -1.79616757]]), array([[ 3.85078651, -0.06942911, -1.96841939,  1.31787302, -2.85952737]]), array([[-3.14286324, -3.37264151, -3.07747957,  4.95473144,  5.29983721]])]\n",
      "cost_list=[0.0017908520361779512, 0.4857234080683734, 0.08556731896663128]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding:utf-8 -*-\n",
    "# author: 徐聪\n",
    "# datetime: 2022-10-04 19:25\n",
    "# software: PyCharm\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class LogisticModel:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def h_theta(self, X, theta):\n",
    "        \"\"\"\n",
    "        计算逻辑回归定义式\n",
    "        :param X: 特征向量\n",
    "        :param theta: 参数\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.sigmoid(np.dot(X, theta.T))\n",
    "\n",
    "    def train(self, x, y, alpha, epochs):\n",
    "        \"\"\"\n",
    "        对数回归模型训练函数\n",
    "        :param x: 特征向量\n",
    "        :param y: 标记\n",
    "        :param alpha: 学习率\n",
    "        :param epochs: 训练次数\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # 初始化参数以及数据\n",
    "        num_train, num_feature = x.shape\n",
    "        X = np.append(np.ones((num_train, 1)), x, axis=1)\n",
    "        theta = np.zeros((1, num_feature + 1))\n",
    "        cost_list = []\n",
    "\n",
    "        # 训练模型\n",
    "        for epoch in range(epochs):\n",
    "            h_theta_x = self.h_theta(X, theta)\n",
    "            # 损失值\n",
    "            cost = -1 / num_train * np.sum(y * np.log(h_theta_x) + (1 - y) * np.log(1 - h_theta_x))\n",
    "            # 计算theta偏导\n",
    "            d_theta = 1 / num_train * np.sum((h_theta_x - y) * X, axis=0)\n",
    "            # 更新theta\n",
    "            theta = theta - alpha * d_theta\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                cost_list.append(cost)\n",
    "                print(f\"epoch={epoch}, cost={cost}\")\n",
    "\n",
    "        return theta, cost_list\n",
    "\n",
    "    def predict(self, x, theta):\n",
    "        \"\"\"\n",
    "        二分类模型预测\n",
    "        :param x: 特征向量\n",
    "        :param theta: 参数\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        num_predict, num_feature = x.shape\n",
    "        X = np.append(np.ones((num_predict, 1)), x, axis=1)\n",
    "        y_predict = self.h_theta(X, theta)\n",
    "        for i in range(len(y_predict)):\n",
    "            if y_predict[i] > 0.5:\n",
    "                y_predict[i] = 1\n",
    "            else:\n",
    "                y_predict[i] = 0\n",
    "        return y_predict\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        定义sigmoid函数\n",
    "        :param x:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def multi_predict(self, x, theta_list):\n",
    "        \"\"\"\n",
    "        多分类器预测\n",
    "        :param x: 特征向量\n",
    "        :param theta_list: 参数\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        num_predict, num_feature = x.shape\n",
    "        X = np.append(np.ones((num_predict, 1)), x, axis=1)\n",
    "\n",
    "        Y_predict = self.h_theta(X, theta_list[0])\n",
    "        y_predict = np.ones((num_predict, 1))\n",
    "        for theta in theta_list[1:]:\n",
    "            Y_predict = np.append(Y_predict, self.h_theta(X, theta), axis=1)\n",
    "\n",
    "        # print(Y_predict)\n",
    "\n",
    "        for i in range(num_predict):\n",
    "            y_predict[i] = np.argmax(Y_predict[i, :])\n",
    "        return y_predict\n",
    "\n",
    "\n",
    "    def multi_train(self, x, y, alpha, epochs):\n",
    "        \"\"\"\n",
    "        多分类器训练\n",
    "        :param x: 特征向量\n",
    "        :param y: 标签\n",
    "        :param alpha: 学习率\n",
    "        :param epochs: 训练次数\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # 获取数据集参数\n",
    "        sort_list = np.unique(y)\n",
    "        num_sort = len(sort_list)\n",
    "        num_train, num_feature = x.shape\n",
    "\n",
    "        theta_list = []\n",
    "        cost_list = []\n",
    "        for i in range(num_sort):\n",
    "            print(f\"==== classifier {sort_list[i]} train begin ====\")\n",
    "            # 获取当前分类label\n",
    "            sort = sort_list[i]\n",
    "            # 将当前分类的label变为1，其余变为0\n",
    "            Y = np.copy(y)\n",
    "            Y[Y != sort] = -1\n",
    "            Y[Y == sort] = 1\n",
    "            Y[Y == -1] = 0\n",
    "\n",
    "            # 存储参数\n",
    "            theta, costs = self.train(x, Y, alpha, epochs)\n",
    "            theta_list.append(theta)\n",
    "            cost_list.append(costs[-1])\n",
    "\n",
    "        return theta_list, cost_list\n",
    "\n",
    "# 获取鸢尾花数据集\n",
    "iris = load_iris()\n",
    "x, y = iris.data, iris.target.reshape(-1, 1).astype('i4')\n",
    "data = np.append(x, y, axis=1)\n",
    "df = pd.DataFrame(data)\n",
    "df.columns = [\"花萼长\", \"花萼宽\", \"花瓣长\", \"花瓣宽\", \"品种\"]\n",
    "print(df)\n",
    "\n",
    "# 训练集和测试集切分\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# 训练模型\n",
    "lm = LogisticModel()\n",
    "# 0.1 5000 达到100%\n",
    "theta_list, cost_list = lm.multi_train(x_train, y_train, 0.1, 5000)\n",
    "print(f\"theta_list={theta_list}\\ncost_list={cost_list}\")\n",
    "\n",
    "# 模型准确性分析\n",
    "print(classification_report(y_test, lm.multi_predict(x_test, theta_list)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8",
   "language": "python",
   "name": "pytorch-1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
